<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Drift Monitor</title>
    <link rel="stylesheet" href="css/style.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <h1>LLM Drift Monitor</h1>

    <div class="explanation">
        <h2>About This Project</h2>
        <p>
            This dashboard monitors Large Language Models (LLMs) for "drift" and "pollution." We periodically ask a set of sensitive, geopolitically relevant questions to six major LLMs: ChatGPT, Claude, Mistral, Gemini, Grok, and Deepseek.
        </p>
        <p>
            <strong>Drift</strong> refers to changes in a model's responses over time. We measure this using a semantic similarity score, which compares each new answer to the previous one. A high score (near 100%) means the answer is very similar, while a low score indicates a significant change. The chart below visualizes this drift score over time.
        </p>
        <p>
            The table shows the raw responses from each model. You can select a specific question from the dropdown to analyze its drift and see the corresponding answers.
        </p>
        <button id="show-questions-btn">View Monitored Questions</button>
    </div>

    <div class="container">
        <div id="controls">
            <label for="question-select">Select a question to analyze:</label>
            <select id="question-select"></select>
        </div>
        <div id="chart-container">
            <canvas id="drift-chart"></canvas>
        </div>
        <div id="app"></div>
    </div>

    <div id="questions-modal" class="modal">
        <div class="modal-content">
            <span class="close-btn">&times;</span>
            <h2>Monitored Questions</h2>
            <ul id="questions-list"></ul>
        </div>
    </div>
    <script src="js/main.js"></script>
</body>
</html>
